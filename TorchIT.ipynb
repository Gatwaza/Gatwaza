{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP8WWqqHfO5tz5AdqzDYHfE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Gatwaza/Gatwaza/blob/main/TorchIT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "\n",
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES\n",
        "# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "CHUNK_SIZE = 40960\n",
        "DATA_SOURCE_MAPPING = 'human-detection-dataset:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F717483%2F3174587%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240318%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240318T092116Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D92b5e49ac5daedaea129777c54eeb56394aa2018d903b802e24be51f685d6ee4738e25c910b5b331bd115239539756f3f6789e2fb60140841d5aa02a2a148dab8a597f99551d4ac18aecfef72d6a53eed0a04e58bcb00d6e546a2ac313cf02037535960dbcfdf31a093f3ad2ed8a86411e0caba4989054ef882de9e769b1224d838eb9acdbf0f05c416e08635d6b6673e9d7936db1e62148747c00e6fdb97540276e0197a9e99bbad96c18d6fc66bd5a37ef728c1d2f9e00e589411a260f30e0fd6beb89140311a2ea11f79746118d10ecbc119629ff2164593d6d63858441ea556c6067e9b5780a9857decd3a2fb30ec4c5a1886793b75c3f4f1206571d3f4e'\n",
        "\n",
        "KAGGLE_INPUT_PATH='/kaggle/input'\n",
        "KAGGLE_WORKING_PATH='/kaggle/working'\n",
        "KAGGLE_SYMLINK='kaggle'\n",
        "\n",
        "!umount /kaggle/input/ 2> /dev/null\n",
        "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
        "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
        "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "try:\n",
        "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "try:\n",
        "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path\n",
        "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
        "    try:\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            data = fileres.read(CHUNK_SIZE)\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)\n",
        "                tfile.write(data)\n",
        "                done = int(50 * dl / int(total_length))\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "                data = fileres.read(CHUNK_SIZE)\n",
        "            if filename.endswith('.zip'):\n",
        "              with ZipFile(tfile) as zfile:\n",
        "                zfile.extractall(destination_path)\n",
        "            else:\n",
        "              with tarfile.open(tfile.name) as tarfile:\n",
        "                tarfile.extractall(destination_path)\n",
        "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "    except HTTPError as e:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "        continue\n",
        "    except OSError as e:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "        continue\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eQA5JCR_3YYM",
        "outputId": "af99d71b-3e42-483a-fef4-644d1333dbe4"
      },
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading human-detection-dataset, 272336530 bytes compressed\n",
            "[==================================================] 272336530 bytes downloaded\n",
            "Downloaded and uncompressed: human-detection-dataset\n",
            "Data source import complete.\n"
          ]
        }
      ],
      "execution_count": 7
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "5bwWptpbIaJ0"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.applications import MobileNetV2 #Pre-trained deep learning model for image classification.\n",
        "from tensorflow.keras.optimizers import Adam #an optimization algorithm for weights update\n",
        "from tensorflow.keras.models import Sequential #represents a linear stack of layers.\n",
        "from tensorflow.keras.utils import to_categorical #convert integer class labels into one-hot encoded vectors.\n",
        "from sklearn.model_selection import train_test_split #split data into training and testing sets for model evaluation.\n",
        "from tensorflow.keras.layers import Dense, Flatten, BatchNormalization, Dropout #connected layer, flatten input into 1D array, normalizes the activations of previous layer and applies dropout regularization to the inputs.\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, array_to_img #image preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "main_dir = \"/kaggle/input/human-detection-dataset/human detection dataset\"\n"
      ],
      "metadata": {
        "id": "rA14RLtRtDkl"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and preprocess your dataset\n",
        "def read_and_preprocess_image(image_path):\n",
        "    image = cv2.imread(image_path, 1)\n",
        "    image = cv2.resize(image, (224, 224))  # Resize to the input size of MobileNetV2\n",
        "    return image"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-20T17:51:43.020256Z",
          "iopub.execute_input": "2024-02-20T17:51:43.020723Z",
          "iopub.status.idle": "2024-02-20T17:51:43.028632Z",
          "shell.execute_reply.started": "2024-02-20T17:51:43.020696Z",
          "shell.execute_reply": "2024-02-20T17:51:43.027767Z"
        },
        "trusted": true,
        "id": "f8IDOrwk3YYP"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = []\n",
        "labels = []\n",
        "\n",
        "for class_name in os.listdir(main_dir):\n",
        "    class_dir = os.path.join(main_dir, class_name)\n",
        "    for image_file in os.listdir(class_dir):\n",
        "        image_path = os.path.join(class_dir, image_file)\n",
        "        image = read_and_preprocess_image(image_path)\n",
        "        data.append(image)\n",
        "        labels.append(int(class_name))  # Assuming class names are 0 and 1\n",
        "\n",
        "# Convert labels to one-hot encoding\n",
        "labels = to_categorical(labels, num_classes=2)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-20T17:51:43.029997Z",
          "iopub.execute_input": "2024-02-20T17:51:43.030591Z",
          "iopub.status.idle": "2024-02-20T17:51:59.724425Z",
          "shell.execute_reply.started": "2024-02-20T17:51:43.030554Z",
          "shell.execute_reply": "2024-02-20T17:51:59.723083Z"
        },
        "trusted": true,
        "id": "64f_6DTi3YYP"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(data[0])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-20T17:51:59.727396Z",
          "iopub.execute_input": "2024-02-20T17:51:59.72772Z",
          "iopub.status.idle": "2024-02-20T17:51:59.736112Z",
          "shell.execute_reply.started": "2024-02-20T17:51:59.727695Z",
          "shell.execute_reply": "2024-02-20T17:51:59.734797Z"
        },
        "trusted": true,
        "id": "H8n23fop3YYP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1a82813-0ab1-435d-db4f-5e3c4471e089"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "224"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-20T17:51:59.737784Z",
          "iopub.execute_input": "2024-02-20T17:51:59.738147Z",
          "iopub.status.idle": "2024-02-20T17:51:59.74903Z",
          "shell.execute_reply.started": "2024-02-20T17:51:59.738114Z",
          "shell.execute_reply": "2024-02-20T17:51:59.747928Z"
        },
        "trusted": true,
        "id": "hQdTiGJG3YYP"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(X_train))\n",
        "print(len(X_test))\n",
        "print(len(y_train))\n",
        "print(len(y_test))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-20T17:51:59.751626Z",
          "iopub.execute_input": "2024-02-20T17:51:59.752768Z",
          "iopub.status.idle": "2024-02-20T17:51:59.757865Z",
          "shell.execute_reply.started": "2024-02-20T17:51:59.752722Z",
          "shell.execute_reply": "2024-02-20T17:51:59.75679Z"
        },
        "trusted": true,
        "id": "icRqfLkB3YYP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bcc5e4bb-7d48-40f8-f924-8b7d2b052b0b"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "736\n",
            "185\n",
            "736\n",
            "185\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data augmentation\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-20T17:51:59.759014Z",
          "iopub.execute_input": "2024-02-20T17:51:59.760495Z",
          "iopub.status.idle": "2024-02-20T17:51:59.768693Z",
          "shell.execute_reply.started": "2024-02-20T17:51:59.760458Z",
          "shell.execute_reply": "2024-02-20T17:51:59.767347Z"
        },
        "trusted": true,
        "id": "QjxQkNGq3YYP"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model architecture\n",
        "model = Sequential()\n",
        "base_model = MobileNetV2(input_shape=(224, 224, 3))\n",
        "model.add(base_model)\n",
        "model.add(Flatten())\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(2, activation='softmax'))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-20T17:54:39.701492Z",
          "iopub.execute_input": "2024-02-20T17:54:39.702404Z",
          "iopub.status.idle": "2024-02-20T17:55:01.050813Z",
          "shell.execute_reply.started": "2024-02-20T17:54:39.702373Z",
          "shell.execute_reply": "2024-02-20T17:55:01.048982Z"
        },
        "trusted": true,
        "id": "rrJYy2Fh3YYQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01cd6db1-92ee-47b3-b6c8-a50c4874cedf"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224.h5\n",
            "14536120/14536120 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-20T17:29:41.825326Z",
          "iopub.status.idle": "2024-02-20T17:29:41.826521Z",
          "shell.execute_reply.started": "2024-02-20T17:29:41.826265Z",
          "shell.execute_reply": "2024-02-20T17:29:41.826293Z"
        },
        "trusted": true,
        "id": "cWeXCPaQ3YYQ"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model with data augmentation\n",
        "batch_size = 32\n",
        "epochs = 20\n",
        "\n",
        "history = model.fit(datagen.flow(np.array(X_train), y_train, batch_size=batch_size),\n",
        "                    steps_per_epoch=len(X_train) / batch_size,\n",
        "                    epochs=epochs,\n",
        "                    validation_data=(np.array(X_test), y_test))"
      ],
      "metadata": {
        "trusted": true,
        "id": "1LHoxc-93YYQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3cbada13-d6e5-47f6-a78f-ddac21cee8d2"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "23/23 [==============================] - 155s 6s/step - loss: 0.4488 - accuracy: 0.8125 - val_loss: 0.7287 - val_accuracy: 0.5676\n",
            "Epoch 2/20\n",
            "23/23 [==============================] - 120s 5s/step - loss: 0.3904 - accuracy: 0.8370 - val_loss: 0.7404 - val_accuracy: 0.5676\n",
            "Epoch 3/20\n",
            "23/23 [==============================] - 121s 5s/step - loss: 0.3108 - accuracy: 0.8723 - val_loss: 0.7829 - val_accuracy: 0.5676\n",
            "Epoch 4/20\n",
            "23/23 [==============================] - 118s 5s/step - loss: 0.3244 - accuracy: 0.8560 - val_loss: 0.7472 - val_accuracy: 0.5676\n",
            "Epoch 5/20\n",
            "23/23 [==============================] - 126s 5s/step - loss: 0.3012 - accuracy: 0.8832 - val_loss: 0.9135 - val_accuracy: 0.5892\n",
            "Epoch 6/20\n",
            "23/23 [==============================] - 121s 5s/step - loss: 0.2443 - accuracy: 0.9226 - val_loss: 0.8972 - val_accuracy: 0.5676\n",
            "Epoch 7/20\n",
            "23/23 [==============================] - 126s 5s/step - loss: 0.2364 - accuracy: 0.9062 - val_loss: 1.0501 - val_accuracy: 0.5676\n",
            "Epoch 8/20\n",
            "23/23 [==============================] - 123s 5s/step - loss: 0.2613 - accuracy: 0.9008 - val_loss: 0.9173 - val_accuracy: 0.5676\n",
            "Epoch 9/20\n",
            "23/23 [==============================] - 123s 5s/step - loss: 0.2408 - accuracy: 0.9144 - val_loss: 1.0767 - val_accuracy: 0.5676\n",
            "Epoch 10/20\n",
            "23/23 [==============================] - 123s 5s/step - loss: 0.2229 - accuracy: 0.9198 - val_loss: 1.1292 - val_accuracy: 0.5676\n",
            "Epoch 11/20\n",
            "23/23 [==============================] - 121s 5s/step - loss: 0.2044 - accuracy: 0.9198 - val_loss: 1.2326 - val_accuracy: 0.5676\n",
            "Epoch 12/20\n",
            "23/23 [==============================] - 119s 5s/step - loss: 0.2049 - accuracy: 0.9144 - val_loss: 1.0393 - val_accuracy: 0.5676\n",
            "Epoch 13/20\n",
            "23/23 [==============================] - 120s 5s/step - loss: 0.2358 - accuracy: 0.9239 - val_loss: 1.2163 - val_accuracy: 0.5676\n",
            "Epoch 14/20\n",
            "23/23 [==============================] - 121s 5s/step - loss: 0.2028 - accuracy: 0.9280 - val_loss: 1.5723 - val_accuracy: 0.5676\n",
            "Epoch 15/20\n",
            "23/23 [==============================] - 123s 5s/step - loss: 0.2424 - accuracy: 0.9130 - val_loss: 1.5883 - val_accuracy: 0.5676\n",
            "Epoch 16/20\n",
            "23/23 [==============================] - 118s 5s/step - loss: 0.1934 - accuracy: 0.9348 - val_loss: 1.5525 - val_accuracy: 0.5676\n",
            "Epoch 17/20\n",
            "23/23 [==============================] - 119s 5s/step - loss: 0.1838 - accuracy: 0.9334 - val_loss: 1.8074 - val_accuracy: 0.5676\n",
            "Epoch 18/20\n",
            "23/23 [==============================] - 120s 5s/step - loss: 0.1731 - accuracy: 0.9402 - val_loss: 1.7465 - val_accuracy: 0.5676\n",
            "Epoch 19/20\n",
            "23/23 [==============================] - 120s 5s/step - loss: 0.1221 - accuracy: 0.9511 - val_loss: 1.7718 - val_accuracy: 0.5676\n",
            "Epoch 20/20\n",
            "23/23 [==============================] - 119s 5s/step - loss: 0.1527 - accuracy: 0.9538 - val_loss: 1.7982 - val_accuracy: 0.5676\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import TensorFlow\n",
        "import tensorflow as tf\n",
        "\n",
        "# Save the trained model to TensorFlow Lite format\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# Save the TensorFlow Lite model to a file\n",
        "with open('TorchIt.tflite', 'wb') as f:\n",
        "    f.write(tflite_model)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-19T11:50:48.25351Z",
          "iopub.status.idle": "2023-12-19T11:50:48.253824Z",
          "shell.execute_reply.started": "2023-12-19T11:50:48.253668Z",
          "shell.execute_reply": "2023-12-19T11:50:48.253682Z"
        },
        "trusted": true,
        "id": "YE9VYCPI3YYQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0a567e2-bbca-46c2-b878-e774c4c7678e"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`mobilenetv2_1.00_224_input` is not a valid tf.function parameter name. Sanitizing to `mobilenetv2_1_00_224_input`.\n",
            "WARNING:absl:`mobilenetv2_1.00_224_input` is not a valid tf.function parameter name. Sanitizing to `mobilenetv2_1_00_224_input`.\n",
            "WARNING:absl:`mobilenetv2_1.00_224_input` is not a valid tf.function parameter name. Sanitizing to `mobilenetv2_1_00_224_input`.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "# Load the TFLite model\n",
        "tflite_model_path = 'TorchIt.tflite'\n",
        "tflite_model = tf.lite.Interpreter(model_path=tflite_model_path)\n",
        "\n",
        "# Convert TFLite to TensorFlow SavedModel\n",
        "saved_model_path = 'TorchIt'\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS]\n",
        "converter.experimental_new_converter = True  # Use the new TFLite converter\n",
        "\n",
        "# Convert and save the model\n",
        "tf_saved_model = converter.convert()\n",
        "with tf.io.gfile.GFile('TorchIt/saved_model.pb', 'wb') as f:\n",
        "    f.write(tf_saved_model)\n"
      ],
      "metadata": {
        "id": "EpN7ghMN3YYQ"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "source": [
        "!ls\n"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NBVjmiCRbMcB",
        "outputId": "9407adf5-6340-4c2c-b0eb-08c2a49ae587"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sample_data  TorchIt  TorchIt.tflite\n"
          ]
        }
      ]
    }
  ]
}